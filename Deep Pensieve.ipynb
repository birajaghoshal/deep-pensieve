{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Pensieve™\n",
    "A Deep Residual MMD Variational Auto-Encoder with Group Normalization (GN), Efficient Sub-Pixel Convolution Super-Resolution (ESPCN), and Perceptual Similarity Loss (SSIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td><img src='https://s3.amazonaws.com/neurokinetikz/latent-animation-1540551741.4923084-final.gif'></td>\n",
    "<td><img src='https://s3.amazonaws.com/neurokinetikz/latent-animation-1540552110.470284-final.gif'></td>\n",
    "<td><img src=\"https://s3.amazonaws.com/neurokinetikz/1542113809.6163912-080.gif\"></td>\n",
    "<td><img src='https://s3.amazonaws.com/neurokinetikz/latent-animation-1540552122.395882-final.gif'></td>\n",
    "<td><img src='https://s3.amazonaws.com/neurokinetikz/latent-animation-1540551578.5925505-final.gif'></td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Stage Variational Auto-Encoders for Coarse-to-Fine Image Generation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1705.07202\n",
    "\n",
    "<img src=\"https://s3.amazonaws.com/neurokinetikz/download-1.png\">\n",
    "\n",
    "Variational auto-encoder (VAE) is a powerful unsupervised learning framework for image generation. One drawback of VAE is that it generates blurry images due to its Gaussianity assumption and thus L2 loss. To allow the generation of high quality images by VAE, we increase the capacity of decoder network by employing residual blocks and skip connections, which also enable efficient optimization. To overcome the limitation of L2 loss, we propose to generate images in a multi-stage manner from coarse to fine. In the simplest case, the proposed multi-stage VAE divides the decoder into two components in which the second component generates refined images based on the course images generated by the first component. Since the second component is independent of the VAE model, it can employ other loss functions beyond the L2 loss and different model architectures. The proposed framework can be easily generalized to contain more than two components. Experiment results on the MNIST and CelebA datasets demonstrate that the proposed multi-stage VAE can generate sharper images as compared to those from the original VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from libs import utils, gif\n",
    "from libs.group_norm import GroupNormalization\n",
    "\n",
    "from keras.models import Model, load_model, model_from_json\n",
    "from keras.layers import Input, Flatten, Reshape, Add, Multiply, Activation, Lambda\n",
    "from keras.layers import Dense, Conv2D, SeparableConv2D, MaxPooling2D, UpSampling2D, GlobalAveragePooling2D\n",
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "\n",
    "from keras_contrib.losses import DSSIMObjective\n",
    "from keras_contrib.layers.convolutional import SubPixelUpscaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = 'roadtrip'\n",
    "\n",
    "SIZE = 128\n",
    "CHANNELS = 3\n",
    "\n",
    "FEATURES = SIZE*SIZE*CHANNELS\n",
    "FEATURES_2X = 2*SIZE*2*SIZE*CHANNELS\n",
    "\n",
    "MODEL_NAME = DIRECTORY+'-'+str(SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images:\t184\n",
      "Loading images:\t184\n",
      "MODEL:  roadtrip-128\n",
      "IMGS:  (184, 128, 128, 3) (184, 256, 256, 3)\n",
      "FLAT:  (184, 49152) (184, 196608)\n",
      "SAMPLES:  (9, 49152) (9, 196608)\n"
     ]
    }
   ],
   "source": [
    "# load images\n",
    "imgs, xs, ys  = utils.load_images(directory=\"imgs/\"+DIRECTORY,rx=SIZE,ry=SIZE)\n",
    "imgs_2x, xs_2x, ys_2x = utils.load_images(directory=\"imgs/\"+DIRECTORY,rx=2*SIZE,ry=2*SIZE)\n",
    "\n",
    "# normalize pixels\n",
    "IMGS = imgs/127.5 - 1\n",
    "FLAT = np.reshape(IMGS,(-1,FEATURES))\n",
    "\n",
    "IMGS_2X = imgs_2x/127.5 - 1\n",
    "FLAT_2X = np.reshape(IMGS_2X,(-1,FEATURES_2X)) \n",
    "\n",
    "SAMPLES =  np.random.permutation(FLAT)[:9]\n",
    "SAMPLES_2X =  np.random.permutation(FLAT_2X)[:9]\n",
    "\n",
    "TOTAL_BATCH = IMGS.shape[0]\n",
    "\n",
    "# print shapes\n",
    "print(\"MODEL: \",MODEL_NAME)\n",
    "print(\"IMGS: \",IMGS.shape,IMGS_2X.shape)\n",
    "print(\"FLAT: \",FLAT.shape,FLAT_2X.shape)\n",
    "print(\"SAMPLES: \",SAMPLES.shape,SAMPLES_2X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very Deep Convolutional Networks for Large-Scale Image Recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1409.1556\n",
    "\n",
    "<img src=\"https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_3/CascadingConvolutions.png\">\n",
    "\n",
    "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3×3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16–19 weight layers.\n",
    "\n",
    "First, we incorporate three non-linear rectification layers instead of a single one, which makes the decision function more discriminative.\n",
    "\n",
    "Second, we decrease the number of parameters: assuming that both the input and the output of a\n",
    "three-layer 3 × 3 convolution stack has C channels, the stack is parametrised by (W) weights; at the same time, a single 7 × 7 conv. layer would require 81% more. This can be seen as imposing a regularisation on the 7 × 7 conv. filters, forcing them to have a decomposition through the 3 × 3 filters (with non-linearity injected in between)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/syncedreview/facebook-ai-proposes-group-normalization-alternative-to-batch-normalization-fb0699bffae7\n",
    "\n",
    "<img src=\"https://s3.amazonaws.com/neurokinetikz/groupnorm.png\">\n",
    "\n",
    "\n",
    "The mainstream normalization technique for almost all convolutional neural networks today is Batch Normalization (BN), which has been widely adopted in the development of deep learning. Proposed by Google in 2015, BN can not only accelerate a model’s converging speed, but also alleviate problems such as Gradient Dispersion in the deep neural network, making it easier to train models.\n",
    "\n",
    "Dr. Wu and Dr. He however argue in their paper Group Normalization that normalizing with batch size has limitations, as BN cannot ensure the model accuracy rate when the batch size becomes smaller. As a result, researchers today are normalizing with large batches, which is very memory intensive, and are avoiding using limited memory to explore higher-capacity models.\n",
    "\n",
    "Dr. Wu and Dr. He believe their new GN technique is a simple but effective alternative to BN. Specifically, GN divides channels — also referred to as feature maps that look like 3D chunks of data — into groups and normalizes the features within each group. GN only exploits the layer dimensions, and its computation is independent of batch sizes.\n",
    "\n",
    "The paper reports that GN had a 10.6% lower error rate than its BN counterpart for ResNet-50 in ImageNet with a batch size of 2 samples; and matched BN performance while outperforming other normalization techniques with a regular batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x):\n",
    "    # set current layer\n",
    "    current_layer = Reshape((SIZE,SIZE,CHANNELS))(x)\n",
    "    \n",
    "    # convolution layers\n",
    "    for layer, n_filters in enumerate(FILTERS):\n",
    "\n",
    "        # stacked 3x3 convolutions with group normalization + activation\n",
    "        current_layer = Conv2D(n_filters,3,padding='SAME',kernel_initializer=INITIALIZER)(current_layer)\n",
    "        current_layer = GroupNormalization(groups=n_filters,axis=-1)(current_layer)\n",
    "        current_layer = Activation(ACTIVATION)(current_layer)\n",
    "\n",
    "        current_layer = Conv2D(n_filters,3,padding='SAME',kernel_initializer=INITIALIZER)(current_layer)\n",
    "        current_layer = GroupNormalization(groups=n_filters,axis=-1)(current_layer)\n",
    "        current_layer = Activation(ACTIVATION)(current_layer)\n",
    "         \n",
    "        # max pooling\n",
    "        current_layer = MaxPooling2D()(current_layer)\n",
    "    \n",
    "    # grab the last shape for reconstruction\n",
    "    shape = current_layer.get_shape().as_list()\n",
    "    \n",
    "    # flatten\n",
    "    flat = Flatten()(current_layer)\n",
    "    \n",
    "    # latent vector\n",
    "    z = Dense(LATENT_DIM,name='encoder')(flat)\n",
    "    \n",
    "    return z, (shape[1],shape[2],shape[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Mean Discrepancy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ermongroup.github.io/blog/a-tutorial-on-mmd-variational-autoencoders/\n",
    "\n",
    "<table><tr>\n",
    "<td><img src=\"https://s3.amazonaws.com/neurokinetikz/kl_latent.gif\" ></td>\n",
    "<td><img src=\"https://s3.amazonaws.com/neurokinetikz/mmd_latent.gif\" ></td>\n",
    "</tr></table>\n",
    "\n",
    "Maximum mean discrepancy (MMD, (Gretton et al. 2007)) is based on the idea that two distributions are identical if and only if all their moments are the same. Therefore, we can define a divergence by measuring how “different” the moments of two distributions p(z) and q(z) are. MMD can accomplish this efficiently via the kernel embedding trick:\n",
    "\n",
    "A kernel can be intuitively interpreted as a function that measures the “similarity” of two samples. It has a large value when two samples are similar, and small when they are different. For example, the Gaussian kernel considers points that are close in Euclidean space to be “similar”. A rough intuition of MMD, then, is that if two distributions are identical, then the average “similarity” between samples from each distribution, should be identical to the average “similarity” between mixed samples from both distributions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kernel(x, y):\n",
    "    x_size = tf.shape(x)[0]\n",
    "    y_size = tf.shape(y)[0]\n",
    "    dim = tf.shape(x)[1]\n",
    "    tiled_x = tf.tile(tf.reshape(x, tf.stack([x_size, 1, dim])), tf.stack([1, y_size, 1]))\n",
    "    tiled_y = tf.tile(tf.reshape(y, tf.stack([1, y_size, dim])), tf.stack([x_size, 1, 1]))\n",
    "    return tf.exp(-tf.reduce_mean(tf.square(tiled_x - tiled_y), axis=2) / tf.cast(dim, tf.float32))\n",
    "\n",
    "def compute_mmd(x, y):\n",
    "    x_kernel = compute_kernel(x, x)\n",
    "    y_kernel = compute_kernel(y, y)\n",
    "    xy_kernel = compute_kernel(x, y)\n",
    "    return tf.reduce_mean(x_kernel) + tf.reduce_mean(y_kernel) - 2 * tf.reduce_mean(xy_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(y_true,y_pred):\n",
    "    epsilon = tf.random_normal(tf.stack([BATCH_SIZE, LATENT_DIM]))\n",
    "    latent_loss = compute_mmd(epsilon, y_pred)\n",
    "    return latent_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deconvolution and Checkerboard Artifacts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://distill.pub/2016/deconv-checkerboard/\n",
    "\n",
    "When we have neural networks generate images, we often have them build them up from low resolution, high-level descriptions. This allows the network to describe the rough image and then fill in the details.\n",
    "\n",
    "In order to do this, we need some way to go from a lower resolution image to a higher one. We generally do this with the deconvolution operation. Roughly, deconvolution layers allow the model to use every point in the small image to “paint” a square in the larger one.\n",
    "\n",
    "Unfortunately, deconvolution can easily have “uneven overlap,” putting more of the metaphorical paint in some places than others. In particular, deconvolution has uneven overlap when the kernel size (the output window size) is not divisible by the stride (the spacing between points on the top). While the network could, in principle, carefully learn weights to avoid this  — as we’ll discuss in more detail later — in practice neural networks struggle to avoid it completely.\n",
    "\n",
    "<img src=\"https://s3.amazonaws.com/neurokinetikz/download-2.png\">\n",
    "\n",
    "To avoid these artifacts, we’d like an alternative to regular deconvolution (“transposed convolution”). Unlike deconvolution, this approach to upsampling shouldn’t have artifacts as its default behavior. Ideally, it would go further, and be biased against such artifacts.\n",
    "\n",
    "One approach is to separate out upsampling to a higher resolution from convolution to compute features. For example, you might resize the image (using nearest-neighbor interpolation or bilinear interpolation) and then do a convolutional layer. This seems like a natural approach, and roughly similar methods have worked well in image super-resolution.\n",
    "\n",
    "Our experience has been that nearest-neighbor resize followed by a convolution works very well, in a wide variety of contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(z,z_g,shape=None):\n",
    "    \n",
    "    # reverse the encoder\n",
    "    filters = FILTERS[::-1]\n",
    "\n",
    "    # inflate\n",
    "    inflated = shape[0]*shape[1]*shape[2]\n",
    "    inflate = Dense(inflated,name='generator')\n",
    "    current_layer = inflate(z) ; generator = inflate(z_g)\n",
    "    \n",
    "    # reshape\n",
    "    reshape = Reshape(shape)\n",
    "    current_layer = reshape(current_layer) ; generator = reshape(generator)\n",
    "    \n",
    "    # build layers\n",
    "    for layer, n_filters in enumerate(filters):\n",
    "        \n",
    "        # upsample\n",
    "        u = UpSampling2D()\n",
    "        current_layer = u(current_layer) ; generator = u(generator)\n",
    "\n",
    "        # stacked 3x3 convolutions with group normalization + activation\n",
    "        c1 = Conv2D(n_filters,3,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "        b1 = GroupNormalization(groups=n_filters,axis=-1)\n",
    "        a1 = Activation(ACTIVATION)\n",
    "\n",
    "        current_layer = c1(current_layer) ; generator = c1(generator)\n",
    "        current_layer = b1(current_layer) ; generator = b1(generator)\n",
    "        current_layer = a1(current_layer) ; generator = a1(generator)\n",
    "\n",
    "        c2 = Conv2D(n_filters,3,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "        b2 = GroupNormalization(groups=n_filters,axis=-1)\n",
    "        a2 = Activation(ACTIVATION)\n",
    "\n",
    "        current_layer = c2(current_layer) ; generator = c2(generator)\n",
    "        current_layer = b2(current_layer) ; generator = b2(generator)\n",
    "        current_layer = a2(current_layer) ; generator = a2(generator)\n",
    "    \n",
    "    # output convolution + activation\n",
    "    conv = Conv2D(CHANNELS,1,padding='SAME',kernel_initializer=INITIALIZER_TANH)\n",
    "    activation = Activation('tanh',name='decoder_dssim')\n",
    "    \n",
    "    current_layer = conv(current_layer)       ; generator = conv(generator)\n",
    "    current_layer = activation(current_layer) ; generator = activation(generator)\n",
    "    \n",
    "    flatten = Flatten(name='decoder')\n",
    "    decoder_loss = flatten(current_layer)\n",
    "    \n",
    "    return current_layer, generator, decoder_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Deep Residual Networks for Single Image Super-Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1707.02921\n",
    "\n",
    "<img src=\"https://s3.amazonaws.com/neurokinetikz/download-3.png\">\n",
    "\n",
    "Recently, residual networks exhibit excellent performance in computer vision problems from the lowlevel to high-level tasks. Although Ledig et al. successfully applied the ResNet architecture to the super-resolution problem with SRResNet, we further improve the performance by employing better ResNet structure.\n",
    "\n",
    "We remove the batch normalization layers from our network as Nah et al.[19] presented in their image deblurring work. Since batch normalization layers normalize the features, they get rid of range flexibility from networks by normalizing the features, it is better to remove them. We experimentally show that this simple modification increases the performance substantially as detailed in\n",
    "\n",
    "Furthermore, GPU memory usage is also sufficiently reduced since the batch normalization layers consume the same amount of memory as the preceding convolutional layers. Our baseline model without batch normalization layer saves approximately 40% of memory usage during training, compared to SRResNet. Consequently, we can build up a larger model that has better performance than conventional ResNet structure under limited computational resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception: Deep Learning with Depthwise Separable Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1610.02357\n",
    "\n",
    "<img width=\"600\" src=\"https://s3.amazonaws.com/neurokinetikz/Screen+Shot+2018-11-24+at+11.19.12+AM.png\">\n",
    "\n",
    "https://stackoverflow.com/questions/52248655/depthwise-separable-convolution/52550451\n",
    "\n",
    "The intuition behind doing this is to decouple the spatial information (width and height) and the depthwise information (channels). While regular convolutional layers will merge feature maps over the number of input channels, depthwise separable convolutions will perform another 1x1 convolution before adding them up.\n",
    "\n",
    "Using a depthwise separable convolutional layer as a drop-in replacement for a regular one will greatly reduce the number of weights in the model. It will also very likely hurt the accuracy due to the much smaller number of weights. However, if you change the width and depth of your architecture to increase the weights again, you may reach the same accuracy of the original model with less parameters. At the same time a depthwise separable model with the same number of weights might achieve a higher accuracy compared the original model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual(x,x_g):\n",
    "    \n",
    "    current_layer = x ; generator = x_g\n",
    "\n",
    "    # shortcuts\n",
    "    shortcut = current_layer \n",
    "    shortcut_g = generator\n",
    "\n",
    "    # conv 1\n",
    "    c1 = SeparableConv2D(R_FILTERS,3,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "    current_layer = c1(current_layer) ; generator = c1(generator)\n",
    "    \n",
    "    # activation 1\n",
    "    a1 = Activation(ACTIVATION)\n",
    "    current_layer = a1(current_layer) ; generator = a1(generator)\n",
    "\n",
    "    # conv 2\n",
    "    c2 = SeparableConv2D(R_FILTERS,3,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "    current_layer = c2(current_layer) ; generator = c2(generator)\n",
    "\n",
    "    # residual scaling\n",
    "    scale = Lambda(lambda x: x * R_SCALING)\n",
    "    current_layer = scale(current_layer) ; generator = scale(generator)\n",
    "\n",
    "    # fix shortcut shape if mismatch\n",
    "    if(shortcut.shape[-1] != current_layer.shape[-1]):\n",
    "        s = SeparableConv2D(R_FILTERS,1,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "        shortcut = s(current_layer) ; shortcut_g = s(generator)\n",
    "        \n",
    "    # merge shortcut\n",
    "    merge = Add()\n",
    "    current_layer = merge([current_layer, shortcut]) ; generator = merge([generator, shortcut_g])\n",
    "\n",
    "    return current_layer, generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1707.02921\n",
    "\n",
    "<img width=500 src=\"https://s3.amazonaws.com/neurokinetikz/Screen+Shot+2018-11-18+at+8.54.43+AM.png\">\n",
    "\n",
    "Recently, the powerful capability of deep neural networks has led to dramatic improvements in SR. Since Dong et al. [4, 5] first proposed a deep learning-based SR method, various CNN architectures have been studied for SR. Kim et al. [11, 12] first introduced the residual network for training much deeper network architectures and achieved superior performance. In particular, they showed that skip connection and recursive convolution alleviate the burden of carrying identity information in the super-resolution network. Similarly to [20], Mao et al. [16] tackled the general image restoration problem with encoder-decoder networks and symmetric skip connections. In [16], they argue that those nested skip connections provide fast and improved convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine(x,x_g):\n",
    "    conv1 = Conv2D(CHANNELS,1,padding='SAME',kernel_initializer=INITIALIZER_TANH)\n",
    "    current_layer = conv1(x) ; generator = conv1(x_g)\n",
    "    \n",
    "    shortcut = current_layer; shortcut_g = generator\n",
    "\n",
    "    for i in range(R_LAYERS):\n",
    "        current_layer, generator = residual(current_layer, generator)\n",
    "#     for i in range(R_GROUPS):\n",
    "#         current_layer, generator = residual_group(current_layer,generator)\n",
    "    \n",
    "    conv2 = Conv2D(CHANNELS,1,padding='SAME',kernel_initializer=INITIALIZER_TANH)\n",
    "    current_layer = conv2(current_layer); generator = conv2(generator)\n",
    "    \n",
    "    merge = Add()\n",
    "    current_layer = merge([current_layer, shortcut]) ; generator = merge([generator, shortcut_g])\n",
    "    \n",
    "    activation = Activation('tanh',name='refiner_dssim')\n",
    "    current_layer = activation(current_layer) ; generator = activation(generator)\n",
    "    \n",
    "    flatten = Flatten(name='refiner')\n",
    "    refiner_loss = flatten(current_layer)\n",
    "    \n",
    "    return current_layer, generator, refiner_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1609.05158\n",
    "\n",
    "<img width=\"75%\" src=\"https://s3.amazonaws.com/neurokinetikz/Screen+Shot+2018-11-23+at+10.26.45+AM.png\">\n",
    "\n",
    "Recently, several models based on deep neural networks have achieved great success in terms of both reconstruction accuracy and computational performance for single image super-resolution. In these methods, the low resolution (LR) input image is upscaled to the high resolution (HR) space using a single filter, commonly bicubic interpolation, before reconstruction. This means that the super-resolution (SR) operation is performed in HR space. We demonstrate that this is sub-optimal and adds computational complexity. \n",
    "\n",
    "In this paper, we present the first convolutional neural network (CNN) capable of real-time SR of 1080p videos on a single K2 GPU. To achieve this, we propose a novel CNN architecture where the feature maps are extracted in the LR space. In addition, we introduce an efficient sub-pixel convolution layer which learns an array of upscaling filters to upscale the final LR feature maps into the HR output. By doing so, we effectively replace the handcrafted bicubic filter in the SR pipeline with more complex upscaling filters specifically trained for each feature map, whilst also reducing the computational complexity of the overall SR operation. \n",
    "\n",
    "We evaluate the proposed approach using images and videos from publicly available datasets and show that it performs significantly better (+0.15dB on Images and +0.39dB on Videos) and is an order of magnitude faster than previous CNN-based methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(x,x_g):\n",
    "    \n",
    "    # current layer\n",
    "    current_layer = x ; generator = x_g\n",
    "    \n",
    "    # convolution\n",
    "    c1 = Conv2D(R_FILTERS*SCALE_FACTOR*SCALE_FACTOR,3,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "    current_layer = c1(current_layer) ; generator = c1(generator)\n",
    "    \n",
    "    # activation\n",
    "    a1 = Activation(ACTIVATION)\n",
    "    current_layer = a1(current_layer) ; generator = a1(generator)\n",
    "    \n",
    "    # sub-pixel upscaling\n",
    "    upscale = SubPixelUpscaling(scale_factor=SCALE_FACTOR)\n",
    "    current_layer = upscale(current_layer); generator = upscale(generator)\n",
    "    \n",
    "    # In practice, it is useful to have a second convolution layer after the \n",
    "    # SubPixelUpscaling layer to speed up the learning process.\n",
    "    c2 = Conv2D(R_FILTERS*SCALE_FACTOR*SCALE_FACTOR,3,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "    current_layer = c2(current_layer) ; generator = c2(generator)\n",
    "    \n",
    "    # activation\n",
    "    a2 = Activation(ACTIVATION)\n",
    "    current_layer = a2(current_layer) ; generator = a2(generator)\n",
    "    \n",
    "    # convolution\n",
    "    c3 = Conv2D(CHANNELS,1,padding='SAME',kernel_initializer=INITIALIZER_TANH)\n",
    "    current_layer = c3(current_layer); generator = c3(generator)\n",
    "    \n",
    "    # activation\n",
    "    a3 = Activation('tanh',name=\"upsampler_dssim\")\n",
    "    current_layer = a3(current_layer) ; generator = a3(generator)\n",
    "    \n",
    "    # flatten\n",
    "    flatten = Flatten(name='upsampler')\n",
    "    upscale_loss = flatten(current_layer)\n",
    "    \n",
    "    return current_layer, generator, upscale_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1511.07289\n",
    "\n",
    "<img width=\"300\" style=\"float:left;\" src=\"https://blogs.mathworks.com/deep-learning/files/2017/12/defining_elu_layer_01.png\">\n",
    "\n",
    "We introduce the \"exponential linear unit\" (ELU) which speeds up learning in deep neural networks and leads to higher classification accuracies. Like rectified linear units (ReLUs), leaky ReLUs (LReLUs) and parametrized ReLUs (PReLUs), ELUs alleviate the vanishing gradient problem via the identity for positive values. However, ELUs have improved learning characteristics compared to the units with other activation functions. \n",
    "\n",
    "In contrast to ReLUs, ELUs have negative values which allows them to push mean unit activations closer to zero like batch normalization but with lower computational complexity. Mean shifts toward zero speed up learning by bringing the normal gradient closer to the unit natural gradient because of a reduced bias shift effect. While LReLUs and PReLUs have negative values, too, they do not ensure a noise-robust deactivation state. ELUs saturate to a negative value with smaller inputs and thereby decrease the forward propagated variation and information. \n",
    "\n",
    "Therefore, ELUs code the degree of presence of particular phenomena in the input, while they do not quantitatively model the degree of their absence. In experiments, ELUs lead not only to faster learning, but also to significantly better generalization performance than ReLUs and LReLUs on networks with more than 5 layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default activation\n",
    "ACTIVATION  = 'elu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1502.01852\n",
    "\n",
    "<img style=\"float:left;\" width=\"300\" src=\"https://s3.amazonaws.com/neurokinetikz/Screen+Shot+2018-11-24+at+12.24.47+PM.png\">\n",
    "Rectifier networks are easier to train compared with traditional sigmoid-like activation networks. But a bad initialization can still hamper the learning of a highly non-linear system. In this subsection, we propose a robust initialization method that removes an obstacle of training extremely deep rectifier networks.\n",
    "\n",
    "It draws samples from a truncated normal distribution centered on 0 with stddev = sqrt(2 / fan_in) where  fan_in is the number of input units in the weight tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters in Action! Part II — Weight Initializers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/hyper-parameters-in-action-part-ii-weight-initializers-35aee1a28404\n",
    "\n",
    "<img width=\"300\" style=\"float:left;\" src=\"https://cdn-images-1.medium.com/max/1600/1*WLUL_bcjsNK9sXNw6nC-cg.png\">\n",
    "\n",
    "If you dug a little bit deeper, you’ve likely also found out that one should use Xavier / Glorot initialization if the activation function is a Tanh, and that He initialization is the recommended one if the activation function is a ReLU.\n",
    "\n",
    "In summary, for a ReLU activated network, the He initialization scheme using an Uniform distribution is a pretty good choice.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializers\n",
    "INITIALIZER = 'he_uniform'\n",
    "INITIALIZER_TANH = 'glorot_uniform'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning to Generate Images with Perceptual Similarity Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1511.06409\n",
    "\n",
    "<img width=\"200\" style=\"float:left;\" src=\"https://s3.amazonaws.com/neurokinetikz/download-4.png\">\n",
    "\n",
    "In this paper, we explore loss functions that, unlike MSE, MAE, and likelihoods, are grounded in human perceptual judgments. We show that these perceptual losses lead to representations are superior to other methods, both with respect to reconstructing given images, and generating novel ones. This superiority is demonstrated both in quantitative studies and human judgements ... We (also) demonstrate that perceptual losses yield a convincing win when applied to a state-of-the-art architecture for single image super-resolution.\n",
    "\n",
    "As observed in the deterministic case, MS-SSIM is better at capturing fine details than either MSE or MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (SIZE == 512):\n",
    "    FILTERS = [64,80,96,112,96,80,64]\n",
    "    \n",
    "elif (SIZE == 256):\n",
    "    FILTERS = [64,96,128,160,112,64]\n",
    "    \n",
    "elif (SIZE == 128):\n",
    "    FILTERS = [64,96,128,96,64]\n",
    "    \n",
    "elif (SIZE == 64):\n",
    "    FILTERS = [32,64,96,64]\n",
    "    \n",
    "elif (SIZE == 32):\n",
    "    FILTERS = [32,64,32]\n",
    "\n",
    "# Residuals\n",
    "R_LAYERS  = 16\n",
    "R_FILTERS = 64\n",
    "R_SCALING = 0.01\n",
    "\n",
    "# Residual channel attention\n",
    "R_GROUPS = 1\n",
    "R_BLOCKS = 16\n",
    "R_REDUCTION = 4\n",
    "\n",
    "# Latent dimension size\n",
    "LATENT_DIM = 512\n",
    "\n",
    "# Scale factor\n",
    "SCALE_FACTOR = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 49152)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 128, 128, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 64) 1792        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_1 (GroupNor (None, 128, 128, 64) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 128, 64) 0           group_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 64) 36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_2 (GroupNor (None, 128, 128, 64) 128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 128, 128, 64) 0           group_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 96)   55392       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_3 (GroupNor (None, 64, 64, 96)   192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 96)   0           group_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 96)   83040       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_4 (GroupNor (None, 64, 64, 96)   192         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 96)   0           group_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 96)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 128)  110720      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_5 (GroupNor (None, 32, 32, 128)  256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 128)  0           group_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 128)  147584      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_6 (GroupNor (None, 32, 32, 128)  256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 128)  0           group_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 128)  0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 96)   110688      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_7 (GroupNor (None, 16, 16, 96)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 96)   0           group_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 96)   83040       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_8 (GroupNor (None, 16, 16, 96)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 96)   0           group_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 96)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 64)     55360       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_9 (GroupNor (None, 8, 8, 64)     128         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 8, 8, 64)     0           group_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 64)     36928       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_10 (GroupNo (None, 8, 8, 64)     128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 8, 8, 64)     0           group_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 4, 4, 64)     0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1024)         0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Dense)                 (None, 512)          524800      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "generator (Dense)               (None, 1024)         525312      encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 4, 4, 64)     0           generator[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 8, 8, 64)     0           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 64)     36928       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_11 (GroupNo (None, 8, 8, 64)     128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 8, 8, 64)     0           group_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 64)     36928       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_12 (GroupNo (None, 8, 8, 64)     128         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 8, 8, 64)     0           group_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 16, 16, 64)   0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 96)   55392       up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_13 (GroupNo (None, 16, 16, 96)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 96)   0           group_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 96)   83040       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_14 (GroupNo (None, 16, 16, 96)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 96)   0           group_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 32, 32, 96)   0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 128)  110720      up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_15 (GroupNo (None, 32, 32, 128)  256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 128)  0           group_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 128)  147584      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_16 (GroupNo (None, 32, 32, 128)  256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 128)  0           group_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 64, 64, 128)  0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 96)   110688      up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_17 (GroupNo (None, 64, 64, 96)   192         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 64, 64, 96)   0           group_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 96)   83040       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_18 (GroupNo (None, 64, 64, 96)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 64, 64, 96)   0           group_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 96) 0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 64) 55360       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_19 (GroupNo (None, 128, 128, 64) 128         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 128, 128, 64) 0           group_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 128, 128, 64) 36928       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_20 (GroupNo (None, 128, 128, 64) 128         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 128, 128, 64) 0           group_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 128, 128, 3)  195         activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dssim (Activation)      (None, 128, 128, 3)  0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 128, 128, 3)  12          decoder_dssim[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 128, 128, 64) 1792        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 128, 128, 64) 0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 128, 128, 64) 36928       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 128, 128, 64) 0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 128, 128, 64) 4160        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 128, 64) 0           lambda_1[0][0]                   \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 128, 128, 64) 36928       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 128, 128, 64) 0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 128, 128, 64) 36928       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 128, 128, 64) 0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 128, 128, 64) 0           lambda_2[0][0]                   \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 128, 128, 64) 36928       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 128, 128, 64) 0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 128, 128, 64) 36928       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 128, 128, 64) 0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 128, 64) 0           lambda_3[0][0]                   \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 128, 128, 64) 36928       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 128, 128, 64) 0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 128, 128, 64) 36928       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 128, 128, 64) 0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 128, 64) 0           lambda_4[0][0]                   \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 128, 128, 64) 36928       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 128, 128, 64) 0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 128, 128, 64) 36928       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 128, 128, 64) 0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 128, 128, 64) 0           lambda_5[0][0]                   \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 128, 128, 64) 36928       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 128, 128, 64) 0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 128, 128, 64) 36928       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 128, 128, 64) 0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 128, 128, 64) 0           lambda_6[0][0]                   \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 128, 128, 64) 36928       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 128, 128, 64) 0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 128, 128, 64) 36928       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 128, 128, 64) 0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 128, 128, 64) 0           lambda_7[0][0]                   \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 128, 128, 64) 36928       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 128, 128, 64) 0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 128, 128, 64) 36928       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 128, 128, 64) 0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 128, 128, 64) 0           lambda_8[0][0]                   \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 128, 128, 64) 36928       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 128, 128, 64) 0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 128, 128, 64) 36928       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 128, 128, 64) 0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 128, 128, 64) 0           lambda_9[0][0]                   \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 128, 128, 64) 36928       add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 128, 128, 64) 0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 128, 128, 64) 36928       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 128, 128, 64) 0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 128, 128, 64) 0           lambda_10[0][0]                  \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 128, 128, 64) 36928       add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 128, 128, 64) 0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 128, 128, 64) 36928       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 128, 128, 64) 0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 128, 128, 64) 0           lambda_11[0][0]                  \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 128, 128, 64) 36928       add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 128, 128, 64) 0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 128, 128, 64) 36928       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 128, 128, 64) 0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 128, 128, 64) 0           lambda_12[0][0]                  \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 128, 128, 64) 36928       add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 128, 128, 64) 0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 128, 128, 64) 36928       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 128, 128, 64) 0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 128, 128, 64) 0           lambda_13[0][0]                  \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 128, 128, 64) 36928       add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 128, 128, 64) 0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 128, 128, 64) 36928       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 128, 128, 64) 0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 128, 128, 64) 0           lambda_14[0][0]                  \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 128, 128, 64) 36928       add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 128, 128, 64) 0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 128, 128, 64) 36928       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 128, 128, 64) 0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 128, 128, 64) 0           lambda_15[0][0]                  \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 128, 128, 64) 36928       add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 128, 128, 64) 0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 128, 128, 64) 36928       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 128, 128, 64) 0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 128, 128, 64) 0           lambda_16[0][0]                  \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 128, 128, 3)  195         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 128, 128, 3)  0           conv2d_56[0][0]                  \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "refiner_dssim (Activation)      (None, 128, 128, 3)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 128, 128, 256 7168        refiner_dssim[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 128, 128, 256 0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_1 (SubPixel (None, 256, 256, 64) 0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 256, 256, 256 147712      sub_pixel_upscaling_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 256, 256, 256 0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 256, 256, 3)  771         activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "upsampler_dssim (Activation)    (None, 256, 256, 3)  0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Flatten)               (None, 49152)        0           decoder_dssim[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "refiner (Flatten)               (None, 49152)        0           refiner_dssim[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "upsampler (Flatten)             (None, 196608)       0           upsampler_dssim[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 3,838,549\n",
      "Trainable params: 3,838,549\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# input\n",
    "X = Input(shape=(FEATURES,))\n",
    "\n",
    "# latent\n",
    "Z, shape = encode(X)\n",
    "\n",
    "# generator input\n",
    "Z_G = Input(shape=(LATENT_DIM,))\n",
    "\n",
    "# coarse reconstruction\n",
    "Y, YG, Y_F = decode(Z,Z_G,shape)\n",
    "\n",
    "# fine reconstruction\n",
    "IMG, IMG_G, IMG_F = refine(Y,YG)\n",
    "\n",
    "# super image resolution\n",
    "IMG_S, IMG_G_S, IMG_S_F = upsample(IMG, IMG_G)\n",
    "    \n",
    "# define autoencoder\n",
    "AUTOENCODER = Model(inputs=[X], outputs=[Z,Y,Y_F,IMG,IMG_F,IMG_S,IMG_S_F])\n",
    "\n",
    "# define encoder\n",
    "ENCODER = Model(inputs=[X], outputs=[Z])\n",
    "\n",
    "# define generator\n",
    "GENERATOR = Model(inputs=[Z_G], outputs=[IMG_G])\n",
    "\n",
    "# define super imager\n",
    "SUPER = Model(inputs=[Z_G], outputs=[IMG_G_S])\n",
    "\n",
    "# define optimizer\n",
    "ADAM = optimizers.Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0, amsgrad=True)\n",
    "\n",
    "# define losses\n",
    "losses = {'encoder':vae_loss,\n",
    "          'decoder':'mse',\n",
    "          'refiner':'mae',\n",
    "          'upsampler':'mae',\n",
    "          'decoder_dssim':DSSIMObjective(),\n",
    "          'refiner_dssim':DSSIMObjective(),\n",
    "          'upsampler_dssim':DSSIMObjective()}\n",
    "\n",
    "# compile models\n",
    "AUTOENCODER.compile(optimizer=ADAM,loss=losses)\n",
    "ENCODER.compile(optimizer=ADAM,loss='mse')\n",
    "GENERATOR.compile(optimizer=ADAM,loss='mse')\n",
    "SUPER.compile(optimizer=ADAM,loss='mse')\n",
    "\n",
    "# print summary\n",
    "AUTOENCODER.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gifit(epoch=None):\n",
    "    if (epoch % GIF_STEPS == 0):\n",
    "        print('saving gif ...')\n",
    "        z,y,yc,i,ic,s,sc = AUTOENCODER.predict_on_batch(SAMPLES)\n",
    "        img = np.clip(127.5*(s+1).reshape((-1, SCALE_FACTOR*SIZE, SCALE_FACTOR*SIZE, CHANNELS)), 0, 255)\n",
    "        RECONS.append(utils.montage(img).astype(np.uint8))\n",
    "        \n",
    "def saveit(epoch=None):\n",
    "    if (epoch > 0 && epoch % MODEL_STEPS == 0):\n",
    "        print('saving model ...')\n",
    "        AUTOENCODER.save(MODEL_NAME+'-autoencoder-model.h5')\n",
    "        ENCODER.save(MODEL_NAME+'-encoder-model.h5')\n",
    "        GENERATOR.save(MODEL_NAME+'-generator-model.h5')\n",
    "        SUPER.save(MODEL_NAME+'-super-model.h5')\n",
    "        print('done')\n",
    "       \n",
    "        \n",
    "# callbacks\n",
    "giffer = LambdaCallback(on_epoch_end=lambda epoch, logs: gifit(epoch))\n",
    "saver = LambdaCallback(on_epoch_end=lambda epoch, logs: saveit(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS      = 12501\n",
    "BATCH_SIZE  = 4\n",
    "\n",
    "MODEL_STEPS = 50\n",
    "GIF_STEPS   = 10\n",
    "\n",
    "SAMPLES =  np.random.permutation(FLAT)[:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RECONS = []\n",
    "\n",
    "# fit model\n",
    "AUTOENCODER.fit(x=FLAT,y=[FLAT,IMGS,FLAT,IMGS,FLAT,IMGS_2X,FLAT_2X],batch_size=BATCH_SIZE,epochs=EPOCHS,callbacks=[giffer,saver])\n",
    "\n",
    "# save training gif\n",
    "gif.build_gif(RECONS, saveto=MODEL_NAME+'-final'+ \"-\"+str(time.time())+'.gif')\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('loading encoder ...', MODEL_NAME)\n",
    "ENCODER = load_model(MODEL_NAME+'-encoder-model.h5')\n",
    "\n",
    "print('loading generator ...')\n",
    "GENERATOR = load_model(MODEL_NAME+'-generator-model.h5',custom_objects={'R_SCALING':R_SCALING})\n",
    "\n",
    "print('loading super ...')\n",
    "SUPER = load_model(MODEL_NAME+'-super-model.h5',custom_objects={'R_SCALING':R_SCALING})\n",
    "\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img width=600 src=\"https://s3.amazonaws.com/neurokinetikz/Screen+Shot+2018-11-13+at+12.17.10+PM.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(index=0):\n",
    "    \n",
    "    # input\n",
    "    x = np.reshape(FLAT[index],(-1,FEATURES))\n",
    "    z = ENCODER.predict_on_batch(x)\n",
    "    \n",
    "    # output\n",
    "    img = np.reshape(GENERATOR.predict_on_batch(z),(-1,FEATURES))\n",
    "    img_s = np.reshape(SUPER.predict_on_batch(z),(-1,FEATURES*SCALE_FACTOR*SCALE_FACTOR))\n",
    "    \n",
    "    # reference\n",
    "    ref = IMGS[index]/2 + .5\n",
    "    ref_s = IMGS_2X[index]/2 + .5\n",
    "    \n",
    "    # denormalize\n",
    "    img = np.reshape(img/2 + .5,(SIZE,SIZE,CHANNELS))\n",
    "    img_s= np.reshape(img_s/2 + .5,(SCALE_FACTOR*SIZE,SCALE_FACTOR*SIZE,CHANNELS))\n",
    "    \n",
    "    # print scores\n",
    "    print(\"PSNR: %.3f %.3f <> MS-SSIM: %.3f %.3f\" % ((utils.psnr(ref,img)),\n",
    "                                                     (utils.psnr(ref_s,img_s)),\n",
    "                                           (utils.MultiScaleSSIM(np.reshape(ref,(1,SIZE,SIZE,CHANNELS)),\n",
    "                                                                 np.reshape(img,(1,SIZE,SIZE,CHANNELS)),\n",
    "                                                                 max_val=1.)),\n",
    "                                            (utils.MultiScaleSSIM(np.reshape(ref_s,(1,SCALE_FACTOR*SIZE,SCALE_FACTOR*SIZE,CHANNELS)),\n",
    "                                                                 np.reshape(img_s,(1,SCALE_FACTOR*SIZE,SCALE_FACTOR*SIZE,CHANNELS)),\n",
    "                                                                 max_val=1.))\n",
    "                                               ))\n",
    "    \n",
    "    # show images\n",
    "    utils.showImagesHorizontally(images=[ref,img])\n",
    "    utils.showImagesHorizontally(images=[ref_s,img_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR: 37.490 31.301 <> MS-SSIM: 0.996 0.984\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 960x640 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 960x640 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reconstruct(random.randint(0,TOTAL_BATCH-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent  Animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.youtube.com/watch?v=grEi3uRlSb4\n",
    "<table><tr>\n",
    "<td><img src=\"https://s3.amazonaws.com/neurokinetikz/1542113809.6163912-109.gif\"></td>\n",
    "<td><img src=\"https://s3.amazonaws.com/neurokinetikz/1542113809.6163912-100.gif\"></td>\n",
    "<td><img src=\"https://s3.amazonaws.com/neurokinetikz/1542113809.6163912-080.gif\"></td>\n",
    "</tr></table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_latents(n_imgs=3,steps=30):\n",
    "    rimgs = np.random.permutation(FLAT)[:n_imgs]\n",
    "    rimgs = np.append(rimgs, [rimgs[0]],axis=0)\n",
    "    latent_animation(rimgs,steps,filename=str(time.time()))\n",
    "\n",
    "def latent_animation(imgs=None,steps=None,filename=\"latent-animation\"):\n",
    "    \n",
    "    # get latent encodings for images\n",
    "    print('getting latent vectors ...')\n",
    "    latents = []\n",
    "    for index,img in enumerate(imgs):\n",
    "        img = np.reshape(img,(-1,FEATURES))\n",
    "        latent = ENCODER.predict_on_batch(img)\n",
    "        latents.append(latent)\n",
    "\n",
    "    # calculate latent path\n",
    "    print('calculating latent path ...')\n",
    "    latent_path = []\n",
    "    for i in range(len(latents)-1):\n",
    "        # get latent vectors\n",
    "        l1 = latents[i] ; l2 = latents[i+1]\n",
    "\n",
    "        # calculate latent distance\n",
    "        image_distance = l2 - l1\n",
    "\n",
    "        # create the latent path\n",
    "        for j in range(steps):\n",
    "            latent_path.append(l1 + j*image_distance/steps)\n",
    "        latent_path.append(l2) \n",
    "    \n",
    "    # reconstruct images along the path\n",
    "    print('reconstructing latent paths... ')\n",
    "    latent_path = np.reshape(latent_path,(-1,LATENT_DIM))\n",
    "    recons = GENERATOR.predict_on_batch(latent_path)\n",
    "\n",
    "    # de-normalize and clip the output\n",
    "    final = np.clip((127.5*(recons+1)).reshape((-1,SIZE,SIZE,CHANNELS)),0,255)\n",
    "\n",
    "    # build the gif\n",
    "    gif.build_gif([utils.montage([r]).astype(np.uint8) for r in final], saveto=filename+\".gif\",dpi=32)\n",
    "    \n",
    "    recons = SUPER.predict_on_batch(latent_path)\n",
    "    final = np.clip((127.5*(recons+1)).reshape((-1,SCALE_FACTOR*SIZE,SCALE_FACTOR*SIZE,CHANNELS)),0,255)\n",
    "    gif.build_gif([utils.montage([r]).astype(np.uint8) for r in final], saveto=filename+\"-2x.gif\",dpi=32)\n",
    "\n",
    "    # done\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting latent vectors ...\n",
      "calculating latent path ...\n",
      "reconstructing latent paths... \n",
      "1543008049.416835\n",
      "getting latent vectors ...\n",
      "calculating latent path ...\n",
      "reconstructing latent paths... \n",
      "1543008076.9144473\n",
      "getting latent vectors ...\n",
      "calculating latent path ...\n",
      "reconstructing latent paths... \n",
      "1543008103.9258192\n",
      "getting latent vectors ...\n",
      "calculating latent path ...\n",
      "reconstructing latent paths... \n",
      "1543008130.7084856\n",
      "getting latent vectors ...\n",
      "calculating latent path ...\n",
      "reconstructing latent paths... \n",
      "1543008157.5956392\n",
      "getting latent vectors ...\n",
      "calculating latent path ...\n",
      "reconstructing latent paths... \n",
      "1543008184.3255377\n",
      "getting latent vectors ...\n",
      "calculating latent path ...\n",
      "reconstructing latent paths... \n",
      "1543008211.4290774\n",
      "getting latent vectors ...\n",
      "calculating latent path ...\n",
      "reconstructing latent paths... \n",
      "1543008238.7169685\n",
      "getting latent vectors ...\n",
      "calculating latent path ...\n",
      "reconstructing latent paths... \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-735a5b4043e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mLATENT_DIM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mrandom_latents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-d25df52e1b26>\u001b[0m in \u001b[0;36mrandom_latents\u001b[0;34m(n_imgs, steps)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_imgs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlatent_animation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrimgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlatent_animation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"latent-animation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-d25df52e1b26>\u001b[0m in \u001b[0;36mlatent_animation\u001b[0;34m(imgs, steps, filename)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# build the gif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mgif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_gif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmontage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaveto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".gif\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mrecons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSUPER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deep-pensieve/libs/gif.py\u001b[0m in \u001b[0;36mbuild_gif\u001b[0;34m(imgs, interval, dpi, save_gif, saveto, show_gif, cmap)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_gif\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mani\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagemagick'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshow_gif\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs)\u001b[0m\n\u001b[1;32m   1172\u001b[0m                         \u001b[0;31m# TODO: See if turning off blit is really necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                         \u001b[0manim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_next_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m                     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrab_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msavefig_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m         \u001b[0;31m# Reconnect signal for first draw if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36msaving\u001b[0;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36mfinish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;34m'''Finish any processing for writing the movie.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrab_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msavefig_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36mcleanup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;34m'''Clean-up and collect the process used to write the movie file.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_frame_sink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0m_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MovieWriter -- Command stdout:\\n%s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communication_started\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   1512\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutExpired\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LATENT_DIM=512\n",
    "for i in range(100):\n",
    "    random_latents(5,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgs =  np.random.permutation(FLAT)\n",
    "t = str(time.time())\n",
    "for i in range(TOTAL_BATCH):\n",
    "    print(i)\n",
    "    latent_animation([imgs[i],imgs[i+1]],200,filename=t+'-'+ ('%03d' % i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model & Continue Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('load model ...')\n",
    "AUTOENCODER = load_model(MODEL_NAME+'-autoencoder-model.h5',\n",
    "                         custom_objects={'vae_loss': vae_loss, \n",
    "                                         'R_SCALING':0.1, \n",
    "                                         'DSSIMObjective':DSSIMObjective()})\n",
    "\n",
    "# define encoder\n",
    "ENCODER = Model(inputs=[AUTOENCODER.input], outputs=[AUTOENCODER.get_layer(\"encoder\").output])\n",
    "\n",
    "# define generator\n",
    "Z = Input(shape=(LATENT_DIM,))\n",
    "GENERATOR = Model(inputs=[Z], outputs=[AUTOENCODER.get_layer(\"generator\")(Z)])\n",
    "\n",
    "ENCODER.compile(optimizer=ADAM,loss='mse')\n",
    "GENERATOR.compile(optimizer=ADAM,loss='mse')\n",
    "\n",
    "print('resume training ...')\n",
    "AUTOENCODER.fit(x=FLAT,y=[FLAT,IMGS,FLAT,IMGS,FLAT],batch_size=BATCH_SIZE,epochs=EPOCHS,callbacks=[giffer,saver])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Channel Attention Network (RCAN) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=600 src=\"https://s3.amazonaws.com/neurokinetikz/Screen+Shot+2018-11-18+at+6.08.27+PM.png\">\n",
    "\n",
    "Convolutional neural network (CNN) depth is of crucial importance for image super-resolution (SR). However, we observe that deeper networks for image SR are more difficult to train. The low resolution inputs and features contain abundant low-frequency information, which is treated equally across channels, hence hindering the representational ability of CNNs. To solve these problems, we propose the very deep residual channel attention networks (RCAN). Specifically, we propose a residual in residual (RIR) structure to form very deep network, which consists of several residual groups with long skip connections. Each residual group contains some residual blocks with short skip connections. Meanwhile, RIR allows abundant low-frequency information to be bypassed through multiple skip connections, making the main network focus on learning high-frequency information. Furthermore, we propose a channel attention mechanism to adaptively rescale channel-wise features by considering interdependencies among channels. Extensive experiments show that our RCAN achieves better accuracy and visual improvements against state-of-the-art methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_group(x,x_g):\n",
    "    # current layer\n",
    "    current_layer = x ; generator = x_g\n",
    "    \n",
    "    # shortcuts\n",
    "    shortcut = current_layer ; shortcut_g = generator\n",
    "    \n",
    "    for i in range(R_BLOCKS):\n",
    "        # attention block\n",
    "        current_layer, generator = attention_block(current_layer, generator)\n",
    "        \n",
    "        # final convolution\n",
    "        if(i+1 == R_BLOCKS):\n",
    "            conv = Conv2D(R_FILTERS,3,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "            current_layer = conv(current_layer) ; generator = conv(generator)\n",
    "    \n",
    "    merge = Add()\n",
    "    current_layer = merge([current_layer, shortcut]) ; generator = merge([generator, shortcut_g])\n",
    "    \n",
    "    return current_layer, generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Channel Attention Block (RCAB) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"500\" src=\"https://s3.amazonaws.com/neurokinetikz/Screen+Shot+2018-11-18+at+6.06.32+PM.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_block(x,x_g):\n",
    "    # current layer\n",
    "    current_layer = x ; generator = x_g\n",
    "    \n",
    "    # shortcuts\n",
    "    shortcut = current_layer ; shortcut_g = generator\n",
    "    \n",
    "     # conv 1\n",
    "    c1 = Conv2D(R_FILTERS,3,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "    current_layer = c1(current_layer) ; generator = c1(generator)\n",
    "    \n",
    "    # activation 1\n",
    "    a1 = Activation(ACTIVATION)\n",
    "    current_layer = a1(current_layer) ; generator = a1(generator)\n",
    "\n",
    "    # conv 2\n",
    "    c2 = Conv2D(R_FILTERS,3,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "    current_layer = c2(current_layer) ; generator = c2(generator)\n",
    "    \n",
    "    scale = Lambda(lambda x: x * R_SCALING)\n",
    "    current_layer = scale(current_layer) ; generator = scale(generator)\n",
    "    \n",
    "    # channel attention\n",
    "    current_layer, generator = channel_attention(current_layer,generator)\n",
    "    \n",
    "    # merge shortcut\n",
    "    merge = Add()\n",
    "    current_layer = merge([current_layer, shortcut]) ; generator = merge([generator, shortcut_g])\n",
    "    \n",
    "    return current_layer, generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel Attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_attention(x,x_g):\n",
    "    # current layer\n",
    "    current_layer = x ; generator = x_g\n",
    "    \n",
    "    # shortcuts\n",
    "    shortcut = current_layer ; shortcut_g = generator\n",
    "    \n",
    "    # global average pooling\n",
    "    gp = GlobalAveragePooling2D()\n",
    "    current_layer = gp(current_layer); generator = gp(generator);\n",
    "    \n",
    "    reshape = Reshape((1,1,R_FILTERS))\n",
    "    current_layer = reshape(current_layer); generator = reshape(generator);\n",
    "        \n",
    "     # conv 1\n",
    "    c1 = Conv2D(int(R_FILTERS/R_REDUCTION),1,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "    current_layer = c1(current_layer) ; generator = c1(generator)\n",
    "\n",
    "    # activation 1\n",
    "    a = Activation(ACTIVATION)\n",
    "    current_layer = a(current_layer) ; generator = a(generator)\n",
    "    \n",
    "    # conv 2\n",
    "    c2 = Conv2D(R_FILTERS,1,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "    current_layer = c2(current_layer) ; generator = c2(generator)\n",
    "    \n",
    "    # residual scaling\n",
    "    scale = Lambda(lambda x: x * R_SCALING)\n",
    "    current_layer = scale(current_layer) ; generator = scale(generator)\n",
    "    \n",
    "    # sigmoid activation\n",
    "    s = Activation(\"sigmoid\")\n",
    "    current_layer = s(current_layer) ; generator = s(generator)\n",
    "    \n",
    "    # merge shortcut\n",
    "    m = Multiply()\n",
    "    current_layer = m([current_layer,shortcut]) ; generator = m([generator,shortcut_g])\n",
    "    \n",
    "    return current_layer, generator\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
