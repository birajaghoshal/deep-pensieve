{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Pensieveâ„¢\n",
    "A Residual Multi-Stage Maximum Mean Discrepancy Variational Resize-Convolution Auto-Encoder with Group Normalization (RMSMMDVRCAECwGN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from libs import utils, gif\n",
    "from libs.group_norm import GroupNormalization\n",
    "\n",
    "from keras.models import Model, load_model, model_from_json\n",
    "from keras.layers import Input, Flatten, Reshape, Add, Multiply, Activation, Lambda\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization\n",
    "from keras.objectives import mean_squared_error, mean_absolute_error\n",
    "from keras.callbacks import ModelCheckpoint, LambdaCallback\n",
    "\n",
    "from keras import optimizers\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = 'roadtrip'\n",
    "\n",
    "SIZE = 256\n",
    "CHANNELS = 3\n",
    "FEATURES = SIZE*SIZE*CHANNELS\n",
    "\n",
    "MODEL_NAME = DIRECTORY+'-'+str(SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "imgs, xs, ys = utils.load_images(directory=DIRECTORY,rx=SIZE,ry=SIZE)\n",
    "\n",
    "# normalize pixels\n",
    "IMGS = imgs/127.5 - 1\n",
    "FLAT = np.reshape(IMGS,(-1,SIZE*SIZE*CHANNELS))\n",
    "SAMPLES =  np.random.permutation(FLAT)[:9]\n",
    "TOTAL_BATCH = IMGS.shape[0]\n",
    "\n",
    "# print shapes\n",
    "print(\"MODEL: \",MODEL_NAME)\n",
    "print(\"IMGS: \",IMGS.shape)\n",
    "print(\"FLAT: \",FLAT.shape)\n",
    "print(\"SAMPLES: \",SAMPLES.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Mean Discrepancy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kernel(x, y):\n",
    "    x_size = tf.shape(x)[0]\n",
    "    y_size = tf.shape(y)[0]\n",
    "    dim = tf.shape(x)[1]\n",
    "    tiled_x = tf.tile(tf.reshape(x, tf.stack([x_size, 1, dim])), tf.stack([1, y_size, 1]))\n",
    "    tiled_y = tf.tile(tf.reshape(y, tf.stack([1, y_size, dim])), tf.stack([x_size, 1, 1]))\n",
    "    return tf.exp(-tf.reduce_mean(tf.square(tiled_x - tiled_y), axis=2) / tf.cast(dim, tf.float32))\n",
    "\n",
    "def compute_mmd(x, y):\n",
    "    x_kernel = compute_kernel(x, x)\n",
    "    y_kernel = compute_kernel(y, y)\n",
    "    xy_kernel = compute_kernel(x, y)\n",
    "    return tf.reduce_mean(x_kernel) + tf.reduce_mean(y_kernel) - 2 * tf.reduce_mean(xy_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x):\n",
    "    # set current layer\n",
    "    current_layer = Reshape((SIZE,SIZE,CHANNELS))(x)\n",
    "    \n",
    "    # convolution layers\n",
    "    for layer, n_filters in enumerate(FILTERS):\n",
    "\n",
    "        # stacked 3x3 convolutions with group normalization + activation\n",
    "        current_layer = Conv2D(n_filters,3,padding='SAME',kernel_initializer=INITIALIZER)(current_layer)\n",
    "        current_layer = GroupNormalization(groups=n_filters,axis=-1)(current_layer)\n",
    "        current_layer = Activation(ACTIVATION)(current_layer)\n",
    "\n",
    "        current_layer = Conv2D(n_filters,3,padding='SAME',kernel_initializer=INITIALIZER)(current_layer)\n",
    "        current_layer = GroupNormalization(groups=n_filters,axis=-1)(current_layer)\n",
    "        current_layer = Activation(ACTIVATION)(current_layer)\n",
    "         \n",
    "        # max pooling\n",
    "        current_layer = MaxPooling2D()(current_layer)\n",
    "    \n",
    "    # grab the last shape for reconstruction\n",
    "    shape = current_layer.get_shape().as_list()\n",
    "    \n",
    "    # flatten\n",
    "    flat = Flatten()(current_layer)\n",
    "    \n",
    "    # latent vector\n",
    "    z = Dense(LATENT_DIM)(flat)\n",
    "    \n",
    "    return z, (shape[1],shape[2],shape[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(z,z_g,shape=None):\n",
    "    \n",
    "    # reverse the encoder\n",
    "    filters = FILTERS[::-1]\n",
    "\n",
    "    # inflate\n",
    "    inflated = shape[0]*shape[1]*shape[2]\n",
    "    inflate = Dense(inflated)\n",
    "    current_layer = inflate(z) ; generator = inflate(z_g)\n",
    "    \n",
    "    # reshape\n",
    "    reshape = Reshape(shape)\n",
    "    current_layer = reshape(current_layer) ; generator = reshape(generator)\n",
    "    \n",
    "    # build layers\n",
    "    for layer, n_filters in enumerate(filters):\n",
    "        \n",
    "        # upsample\n",
    "        u = UpSampling2D()\n",
    "        current_layer = u(current_layer) ; generator = u(generator)\n",
    "\n",
    "        # stacked 3x3 convolutions with group normalization + activation\n",
    "        c1 = Conv2D(n_filters,3,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "        b1 = GroupNormalization(groups=n_filters,axis=-1)\n",
    "        a1 = Activation(ACTIVATION)\n",
    "\n",
    "        current_layer = c1(current_layer) ; generator = c1(generator)\n",
    "        current_layer = b1(current_layer) ; generator = b1(generator)\n",
    "        current_layer = a1(current_layer) ; generator = a1(generator)\n",
    "\n",
    "        c2 = Conv2D(n_filters,3,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "        b2 = GroupNormalization(groups=n_filters,axis=-1)\n",
    "        a2 = Activation(ACTIVATION)\n",
    "\n",
    "        current_layer = c2(current_layer) ; generator = c2(generator)\n",
    "        current_layer = b2(current_layer) ; generator = b2(generator)\n",
    "        current_layer = a2(current_layer) ; generator = a2(generator)\n",
    "    \n",
    "    # output convolution + activation\n",
    "    conv = Conv2D(CHANNELS,1,padding='SAME')\n",
    "    activation = Activation('tanh')\n",
    "    \n",
    "    current_layer = conv(current_layer)       ; generator = conv(generator)\n",
    "    current_layer = activation(current_layer) ; generator = activation(generator)\n",
    "\n",
    "    # flatten\n",
    "    f = Flatten()\n",
    "    current_layer = f(current_layer) ; generator = f(generator)\n",
    "    \n",
    "    return current_layer, generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual(x,x_g):\n",
    "    \n",
    "    current_layer = x ; generator = x_g\n",
    "\n",
    "    # shortcuts\n",
    "    shortcut = current_layer \n",
    "    shortcut_g = generator\n",
    "\n",
    "    # conv 1\n",
    "    c1 = Conv2D(R_FILTERS,3,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "    current_layer = c1(current_layer) ; generator = c1(generator)\n",
    "    \n",
    "    # activation 1\n",
    "    a1 = Activation(ACTIVATION)\n",
    "    current_layer = a1(current_layer) ; generator = a1(generator)\n",
    "\n",
    "    # conv 2\n",
    "    c2 = Conv2D(R_FILTERS,3,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "    current_layer = c2(current_layer) ; generator = c2(generator)\n",
    "\n",
    "    # residual scaling\n",
    "    current_layer = Lambda(lambda x: x * .1)(current_layer)\n",
    "    generator = Lambda(lambda x: x * .1)(generator)\n",
    "\n",
    "    # fix shortcut shape if mismatch\n",
    "    if(shortcut.shape[-1] != current_layer.shape[-1]):\n",
    "        s = Conv2D(R_FILTERS,1,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "        shortcut = s(current_layer) ; shortcut_g = s(generator)\n",
    "        \n",
    "    # merge shortcut\n",
    "    merge = Add()\n",
    "    current_layer = merge([current_layer, shortcut]) ; generator = merge([generator, shortcut_g])\n",
    "\n",
    "    return current_layer, generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine(x,x_g):\n",
    "    \n",
    "    # reshape\n",
    "    reshape = Reshape((SIZE,SIZE,CHANNELS))\n",
    "    current_layer = reshape(x) ; generator = reshape(x_g)\n",
    "\n",
    "    # residual layers\n",
    "    for layer in range(R_LAYERS):\n",
    "    \n",
    "        # residual block\n",
    "        current_layer, generator = residual(current_layer,generator)\n",
    "    \n",
    "    # output convolution + activation\n",
    "    conv = Conv2D(CHANNELS,1,padding='SAME')\n",
    "    activation = Activation('tanh')\n",
    "    \n",
    "    current_layer = conv(current_layer)       ; generator = conv(generator)\n",
    "    current_layer = activation(current_layer) ; generator = activation(generator)\n",
    "    \n",
    "    return Flatten()(current_layer), Flatten()(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECONS = []\n",
    "\n",
    "def gifit(epoch=None):\n",
    "    if (epoch % GIF_STEPS == 0):\n",
    "        print('saving gif ...')\n",
    "        [i,z,y] = AUTOENCODER.predict_on_batch(SAMPLES)\n",
    "        img = np.clip(127.5*(i+1).reshape((-1, SIZE, SIZE, CHANNELS)), 0, 255)\n",
    "        RECONS.append(utils.montage(img).astype(np.uint8))\n",
    "        \n",
    "def saveit(epoch=None):\n",
    "    if (epoch == 0):\n",
    "        print('saving model ...')\n",
    "        with open(MODEL_NAME+'-model.json', 'w') as f:\n",
    "            json.dump(AUTOENCODER.to_json(), f, ensure_ascii=False)\n",
    "            \n",
    "    if (epoch % MODEL_STEPS == 0):\n",
    "        print('saving weights ...')\n",
    "        AUTOENCODER.save_weights(MODEL_NAME+'-weights.h5')\n",
    "        \n",
    "        print('saving encoder ...')\n",
    "        ENCODER.save(MODEL_NAME+'-encoder.hdf5')\n",
    "        \n",
    "        print('saving generator ...')\n",
    "        GENERATOR.save(MODEL_NAME+'-generator.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 512px\n",
    "# FILTERS = [64,80,96,112,96,80,64]\n",
    "\n",
    "# 256px\n",
    "FILTERS = [64,96,128,160,128,64]\n",
    "\n",
    "# Residuals\n",
    "R_LAYERS  = 16\n",
    "R_FILTERS = 64\n",
    "R_SCALING = .1\n",
    "\n",
    "# Default initializer and activation\n",
    "INITIALIZER = 'he_normal'\n",
    "ACTIVATION  = 'elu'\n",
    "\n",
    "# Latent dimension size\n",
    "LATENT_DIM = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS      = 10001\n",
    "BATCH_SIZE  = 8\n",
    "\n",
    "MODEL_STEPS = 50\n",
    "GIF_STEPS   = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# input\n",
    "X = Input(shape=(FEATURES,))\n",
    "\n",
    "# latent\n",
    "Z, shape = encode(X)\n",
    "\n",
    "# latent loss\n",
    "epsilon = tf.random_normal(tf.stack([BATCH_SIZE, LATENT_DIM]))\n",
    "latent_loss = compute_mmd(epsilon, Z)\n",
    "\n",
    "# generator input\n",
    "Z_G = Input(shape=(LATENT_DIM,))\n",
    "\n",
    "# coarse reconstruction\n",
    "Y, YG = decode(Z,Z_G,shape)\n",
    "coarse_loss = mean_squared_error(X,Y)\n",
    "\n",
    "# fine reconstruction\n",
    "IMG, IMG_G = refine(Y,YG)\n",
    "fine_loss = mean_absolute_error(X,IMG)\n",
    "\n",
    "# define autoencoder\n",
    "AUTOENCODER = Model(inputs=[X], outputs=[IMG,Z,Y])\n",
    "AUTOENCODER.add_loss(latent_loss)\n",
    "AUTOENCODER.add_loss(coarse_loss)\n",
    "AUTOENCODER.add_loss(fine_loss)\n",
    "\n",
    "# define encoder\n",
    "ENCODER = Model(inputs=[X], outputs=[Z])\n",
    "\n",
    "# define generator\n",
    "GENERATOR = Model(inputs=[Z_G], outputs=[IMG_G])\n",
    "\n",
    "# define optimizer\n",
    "ADAM = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0, amsgrad=True)\n",
    "\n",
    "# compile models\n",
    "AUTOENCODER.compile(optimizer=ADAM)\n",
    "ENCODER.compile(optimizer=ADAM,loss='mse')\n",
    "GENERATOR.compile(optimizer=ADAM,loss='mse')\n",
    "\n",
    "# print summary\n",
    "AUTOENCODER.summary()\n",
    "\n",
    "# callbacks\n",
    "giffer = LambdaCallback(on_epoch_end=lambda epoch, logs: gifit(epoch))\n",
    "saver = LambdaCallback(on_epoch_end=lambda epoch, logs: saveit(epoch))\n",
    "\n",
    "# fit model\n",
    "AUTOENCODER.fit(x=FLAT,batch_size=BATCH_SIZE,verbose=1,epochs=EPOCHS,shuffle=True,callbacks=[giffer,saver])\n",
    "\n",
    "# save animated gif\n",
    "gif.build_gif(RECONS, saveto=MODEL_NAME+'-final'+ \"-\"+str(time.time())+'.gif')\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('loading encoder ...')\n",
    "ENCODER = load_model(MODEL_NAME+'-encoder.hdf5')\n",
    "\n",
    "print('loading generator ...')\n",
    "GENERATOR = load_model(MODEL_NAME+'-generator.hdf5')\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(index=0):\n",
    "    x = np.reshape(FLAT[index],(-1,FEATURES))\n",
    "    z = np.reshape(ENCODER.predict_on_batch(x),(-1,LATENT_DIM))\n",
    "    y = np.reshape(GENERATOR.predict_on_batch(z),(-1,FEATURES))\n",
    "    \n",
    "    t = IMGS[index]/2 + .5\n",
    "    img = np.reshape(y[0]/2 + .5,(SIZE,SIZE,CHANNELS))\n",
    "    \n",
    "    print(\"PSNR: %.3f\" % utils.psnr(t,img))\n",
    "    print(\"MS-SSIM: %.3f\" % utils.MultiScaleSSIM(np.reshape(t,(1,SIZE,SIZE,CHANNELS)),\n",
    "                                                 np.reshape(img,(1,SIZE,SIZE,CHANNELS)),\n",
    "                                                 max_val=1.))\n",
    "    \n",
    "   \n",
    "    return t, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = random.randint(0,TOTAL_BATCH) ; print(r)\n",
    "orig, img = reconstruct(r)\n",
    "utils.showImagesHorizontally(images=[orig,img])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent  Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_latents(n_imgs=3,path='linear',steps=30,slices=1,directory='roadtrip'):\n",
    "    imgs = np.random.permutation(FLAT)[:n_imgs]\n",
    "    latent_animation(imgs,steps,slices,path=path)\n",
    "\n",
    "def latent_animation(imgs=None,steps=None,slices=None,path=None,filename=\"latent-animation-\"):\n",
    "    # get encodings\n",
    "    print('getting latent vectors ...')\n",
    "    latents = []\n",
    "    for index,img in enumerate(imgs):\n",
    "        img = np.reshape(img,(-1,FEATURES))\n",
    "        latent = ENCODER.predict_on_batch(img)\n",
    "        latents.append(latent)\n",
    "\n",
    "    # calculate latent transitions\n",
    "    print('calculating latent manifold path ...')\n",
    "    recons = []\n",
    "    current_step = None\n",
    "    for i in range(len(latents)-1):\n",
    "        print(\"IMG: \" + str(i))\n",
    "        l1 = latents[i]\n",
    "        l2 = latents[i+1]\n",
    "\n",
    "        # latent image distance\n",
    "        image_distance = l2 - l1\n",
    "\n",
    "        # sine wave for animation steps\n",
    "        integral = steps*(1+np.cos(np.pi/steps))/np.pi\n",
    "        normalizer = image_distance/integral\n",
    "\n",
    "        # start image\n",
    "        current_step = l1\n",
    "        \n",
    "        # build latent vectors to animate transition\n",
    "#         recons.append(l1)\n",
    "#         for i in range(steps):\n",
    "#             if (path == 'contract'):\n",
    "#                 current_step = current_step + normalizer*np.sin(np.pi*i/steps)\n",
    "#             else: # linear\n",
    "#                 current_step = l1 + i*image_distance/steps\n",
    "\n",
    "#             recons.append(current_step)\n",
    "#         recons.append(l2)\n",
    "        \n",
    "        recons.append(l1)\n",
    "        for i in range(steps):\n",
    "            current_step = l1 + i*image_distance/steps\n",
    "            recons.append(current_step)\n",
    "            \n",
    "            if(i > 1 and (i+1) % int(steps/slices) == 0):\n",
    "                print('reconstructing ... ',i)\n",
    "                recons = np.reshape(recons,(-1,LATENT_DIM))\n",
    "                i = GENERATOR.predict_on_batch(recons)\n",
    "\n",
    "                # de-normalize and clip the output\n",
    "                final = np.clip((127.5*(i+1)).reshape((-1,SIZE,SIZE,CHANNELS)),0,255)\n",
    "\n",
    "                # build the gif\n",
    "                filename = filename+str(time.time())\n",
    "                gif.build_gif([utils.montage([r]).astype(np.uint8) for r in final], saveto=filename+\"-final.gif\",dpi=SIZE)\n",
    "\n",
    "                print(filename)\n",
    "                \n",
    "                recons = []\n",
    "                filename=\"latent-animation-\"\n",
    "        recons.append(l2)\n",
    "                \n",
    "#         recons.append(l2)\n",
    "    \n",
    "    # get predictions from latent vectors\n",
    "    print('reconstructing ... ')\n",
    "    recons = np.reshape(recons,(-1,LATENT_DIM))\n",
    "    i = GENERATOR.predict_on_batch(recons)\n",
    "\n",
    "    # de-normalize and clip the output\n",
    "    final = np.clip((127.5*(i+1)).reshape((-1,SIZE,SIZE,CHANNELS)),0,255)\n",
    "\n",
    "    # build the gif\n",
    "    filename = filename+str(time.time())\n",
    "    gif.build_gif([utils.montage([r]).astype(np.uint8) for r in final], saveto=filename+\"-final.gif\",dpi=SIZE)\n",
    "\n",
    "    print(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random_latents(n_imgs=3,steps=160,slices=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs =  np.random.permutation(FLAT)\n",
    "for i in range(TOTAL_BATCH):\n",
    "    print(i)\n",
    "    latent_animation([imgs[i],imgs[i+1]],40)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
